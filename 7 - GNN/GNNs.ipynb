{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_889/3837100366.py:12: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "DATASET_PATH = \"../data\"\n",
    "CHECKPOINT_PATH = \"../saved_models/tutorial7\"\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelMLP.ckpt...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelGNN.ckpt...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/GraphLevelGraphConv.ckpt...\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "# Github URL where saved models are stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/\"\n",
    "# Files to download\n",
    "pretrained_files = [\"NodeLevelMLP.ckpt\", \"NodeLevelGNN.ckpt\", \"GraphLevelGraphConv.ckpt\"]\n",
    "\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if \"/\" in file_name:\n",
    "        os.makedirs(file_path.rsplit(\"/\",1)[0], exist_ok=True)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Neural Networks\n",
    "\n",
    "An **adjacency matrix** is a square matrix whose elements indicate whether pairs of vertices are adjacent (connected or not). $A_{ij}$ is 1 if there is a connection from node $i$ to $j$. FOr an undirected graph, $A$ is a symmetric matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Convolutions\n",
    "\n",
    "GCNs (Graph Convolution Networks) are similar to convolutions in images in the sense that the “filter” parameters are typically shared over all locations in the graph. At the same time, GCNs rely on message passing methods, which means that vertices exchange information with the neighbors, and send “messages” to each other. <br>\n",
    "\n",
    "The first step is that each node creates a feature vector that represents the message that it wants to send. The second step is messages are sent to neighbors so that a node receives one message per adjacent node. <br>\n",
    "\n",
    "An arbritrary number of messages need to be combined in some way for a node to receive them. The usual way to go is to sum or take the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Linear(c_in, c_out) # convert input features to messages\n",
    "\n",
    "    def forward(self, node_feats, adj_matrix):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            node_feats - Tensor with node features of shape [batch, num_nodes, c_in]\n",
    "            adj_matrix - batch of adj matrices of the graph. If there is an edge from i to j,\n",
    "            adj_matrix[b,i,j] = 1 else 0. Supports directed edges by non-symmetric matrices. Assume\n",
    "            to already have added the identity connections (A = A + I since each messages gets \n",
    "            message from itself)\n",
    "        \"\"\"\n",
    "        num_neighbors = adj_matrix.sum(dim=-1, keepdims=True) # get num neighbors for each node\n",
    "                                                              # include itself from A = A + I\n",
    "        node_feats = self.projection(node_feats)\n",
    "        node_feats = torch.bmm(adj_matrix, node_feats)\n",
    "        node_feats = node_feats / num_neighbors # average\n",
    "        return node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features:\n",
      " tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "\n",
      "Adjacency matrix:\n",
      " tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.],\n",
      "         [0., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "node_feats = torch.arange(8, dtype=torch.float32).view(1,4,2)\n",
    "adj_matrix = torch.Tensor([[[1, 1, 0, 0],\n",
    "                            [1, 1, 1, 1],\n",
    "                            [0, 1, 1, 1],\n",
    "                            [0, 1, 1, 1]]])\n",
    "\n",
    "print(\"Node features:\\n\", node_feats)\n",
    "print(\"\\nAdjacency matrix:\\n\", adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.],\n",
      "         [4.],\n",
      "         [3.],\n",
      "         [3.]]])\n",
      "Output features: \n",
      " tensor([[[1., 2.],\n",
      "         [3., 4.],\n",
      "         [4., 5.],\n",
      "         [4., 5.]]])\n"
     ]
    }
   ],
   "source": [
    "# apply GCN layer to above example\n",
    "\n",
    "gcn_layer = GCNLayer(c_in=2, c_out=4)\n",
    "gcn_layer.projection.weight.data = torch.Tensor([[1.0, 0.0],[0.0, 1.0]])\n",
    "gcn_layer.projection.bias.data = torch.Tensor([0.0, 0.0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_feats = gcn_layer(node_feats, adj_matrix)\n",
    "\n",
    "print(\"Output features: \\n\", out_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can see from above that each node's output features are just the average of the summed self and neighbor values. In a GNN, we also want feature exchange between nodes beyond its neighbors. This can be achieved by applying multiple GCN layers. However, one issue we can see from the above example is the output features of 3 and 4 are the same since they have the same adjacent nodes (inclusive of self). Therefore, the GCN layer can make the network forget node-specific info if we just take a mean over all messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aside: Einsum\n",
    "\n",
    "[Tutorial](https://rockt.github.io/2018/04/30/einsum) here.\n",
    "\n",
    "Einsum notation is an elegant way to express ot products, outer products, transposes and matrix-vector or matrix-matrix multiplications. Once you understand and make use of einsum, you will be able to write more concise and efficient code more quickly. When not using einsum it is easy to introduce unnecessary reshaping and transposing of tensors, as well as intermediate tensors that could be omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: \n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "a.T: \n",
      " tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix transpose: B_{ji} = A_{ij}\n",
    "a = torch.arange(6).view(2,3)\n",
    "a_T = torch.einsum(\"ij->ji\", [a])\n",
    "print(\"a: \\n\", a)\n",
    "print(\"a.T: \\n\", a_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: \n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "a_sum: \n",
      " tensor(15)\n"
     ]
    }
   ],
   "source": [
    "# Sum\n",
    "a = torch.arange(6).view(2,3)\n",
    "a_sum = torch.einsum(\"ij->\", [a])\n",
    "print(\"a: \\n\", a)\n",
    "print(\"a_sum: \\n\", a_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: \n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "a_col: \n",
      " tensor([ 3, 12])\n"
     ]
    }
   ],
   "source": [
    "# Column sum\n",
    "a = torch.arange(6).view(2,3)\n",
    "a_col = torch.einsum(\"ij->i\", [a])\n",
    "print(\"a: \\n\", a)\n",
    "print(\"a_col: \\n\", a_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: \n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "a_row: \n",
      " tensor([3, 5, 7])\n"
     ]
    }
   ],
   "source": [
    "# Row sum\n",
    "a = torch.arange(6).view(2,3)\n",
    "a_row = torch.einsum(\"ij->j\", [a])\n",
    "print(\"a: \\n\", a)\n",
    "print(\"a_row: \\n\", a_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: \n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "b: \n",
      " tensor([0, 1, 2])\n",
      "a@b: \n",
      " tensor([ 5, 14])\n"
     ]
    }
   ],
   "source": [
    "# matrix-vector multiplication\n",
    "a = torch.arange(6).view(2,3)\n",
    "b = torch.arange(3)\n",
    "ab = torch.einsum(\"ik,k->i\",[a,b])\n",
    "print(\"a: \\n\", a)\n",
    "print(\"b: \\n\", b)\n",
    "print(\"a@b: \\n\", ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: \n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "b: \n",
      " tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14]])\n",
      "a@b: \n",
      " tensor([[ 25,  28,  31,  34,  37],\n",
      "        [ 70,  82,  94, 106, 118]])\n"
     ]
    }
   ],
   "source": [
    "# matrix-matrix multiplication\n",
    "a = torch.arange(6).view(2,3)\n",
    "b = torch.arange(15).view(3,5)\n",
    "ab = torch.einsum(\"ij,jk->ik\",[a,b])\n",
    "print(\"a: \\n\", a)\n",
    "print(\"b: \\n\", b)\n",
    "print(\"a@b: \\n\", ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: \n",
      " tensor([0, 1, 2])\n",
      "b: \n",
      " tensor([3, 4, 5])\n",
      "a dot b: \n",
      " tensor(14)\n"
     ]
    }
   ],
   "source": [
    "# dot product - vector\n",
    "a = torch.arange(3)\n",
    "b = torch.arange(3,6)\n",
    "a_dot_b = torch.einsum(\"i,i->\", [a,b])\n",
    "print(\"a: \\n\", a)\n",
    "print(\"b: \\n\", b)\n",
    "print(\"a dot b: \\n\", a_dot_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: \n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "b: \n",
      " tensor([[ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "a dot b: \n",
      " tensor(145)\n"
     ]
    }
   ],
   "source": [
    "# dot product - matrix\n",
    "a = torch.arange(6).view(2,3)\n",
    "b = torch.arange(6,12).view(2,3)\n",
    "a_dot_b = torch.einsum(\"ij,ij->\", [a,b])\n",
    "print(\"a: \\n\", a)\n",
    "print(\"b: \\n\", b)\n",
    "print(\"a dot b: \\n\", a_dot_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: \n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "b: \n",
      " tensor([[ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "a dot b: \n",
      " tensor([[ 0,  7, 16],\n",
      "        [27, 40, 55]])\n"
     ]
    }
   ],
   "source": [
    "# Hadamard Product (element wise multiplication)\n",
    "a = torch.arange(6).view(2,3)\n",
    "b = torch.arange(6,12).view(2,3)\n",
    "a_dot_b = torch.einsum(\"ij,ij->ij\",[a,b])\n",
    "print(\"a: \\n\", a)\n",
    "print(\"b: \\n\", b)\n",
    "print(\"a dot b: \\n\", a_dot_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: \n",
      " tensor([0, 1, 2])\n",
      "b: \n",
      " tensor([3, 4, 5, 6])\n",
      "a outer b: \n",
      " tensor([[ 0,  0,  0,  0],\n",
      "        [ 3,  4,  5,  6],\n",
      "        [ 6,  8, 10, 12]])\n"
     ]
    }
   ],
   "source": [
    "# outer product\n",
    "a = torch.arange(3)\n",
    "b = torch.arange(3,7)\n",
    "ab_out = torch.einsum(\"i,j->ij\",[a,b])\n",
    "print(\"a: \\n\", a)\n",
    "print(\"b: \\n\", b)\n",
    "print(\"a outer b: \\n\", ab_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8867, -0.5193,  1.5010],\n",
       "         [-3.2543, -2.6764, -3.8120]],\n",
       "\n",
       "        [[ 0.3917, -1.4145, -1.0164],\n",
       "         [ 1.3699, -1.9413,  1.1569]],\n",
       "\n",
       "        [[-4.2061,  0.9894,  1.4518],\n",
       "         [ 1.1509, -1.6810,  3.5229]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch matrix multiplication\n",
    "a = torch.randn(3,2,5)\n",
    "b = torch.randn(3,5,3)\n",
    "torch.einsum(\"ijk,ikl->ijl\",[a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3270, -2.8548,  1.2384, -0.5307,  0.4338],\n",
       "        [ 1.3352, -5.7957,  3.2069,  1.1042, -6.3094]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bilinear transformation\n",
    "a = torch.randn(2,3)\n",
    "b = torch.randn(5,3,7)\n",
    "c = torch.randn(2,7)\n",
    "torch.einsum(\"ik,jkl,il->ij\",[a,b,c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Attention\n",
    "\n",
    "Similarly to the GCN, the graph attention layer creates a message for each node using a linear layer/weight matrix. For the attention part, it uses the message from the node itself as a query, and the messages to average as both keys and values (note that this also includes the message to itself). The score function $f_{attn}$ is implemented as a one-layer MLP which maps the query and key to a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, c_in, c_out, num_heads=1, concat_heads=True, alpha=0.2):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Dimensionality of input features\n",
    "            c_out - Dimensionality of output features\n",
    "            num_heads - Number of heads, i.e. attention mechanisms to apply in parallel. The\n",
    "                        output features are equally split up over the heads if concat_heads=True.\n",
    "            concat_heads - If True, the output of the different heads is concatenated instead of averaged.\n",
    "            alpha - Negative slope of the LeakyReLU activation.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.concat_heads = concat_heads\n",
    "        if self.concat_heads:\n",
    "            assert c_out % num_heads == 0, \"Number of output features must be a multiple of num_heads\"\n",
    "            c_out = c_out // num_heads\n",
    "\n",
    "        # sub-modules and parameters needed in layer\n",
    "        self.projection = nn.Linear(c_in, c_out * num_heads)\n",
    "        self.a = nn.Parameter(torch.Tensor(num_heads, 2 * c_out)) # one per head; weight matrix of MLP\n",
    "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
    "\n",
    "        # initialization from the original implementation\n",
    "        nn.init.xavier_uniform_(self.projection.weight.data, gain=1.414) # gain is factor for LeakyReLU\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "\n",
    "    def forward(self, node_feats, adj_matrix, print_attn_probs=False):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            node_feats - Input features of the node. Shape: [batch_size, c_in]\n",
    "            adj_matrix - Adjacency matrix including self-connections. Shape: [batch_size, num_nodes, num_nodes]\n",
    "            print_attn_probs - If True, the attention weights are printed during the forward pass (for debugging purposes)\n",
    "        \"\"\"\n",
    "        print(\"Adj matrix shape = \\n\", adj_matrix.shape)\n",
    "        batch_size, num_nodes = adj_matrix.size(0), adj_matrix.size(1)\n",
    "\n",
    "        # apply linear layer and sort nodes by head\n",
    "        print(\"Node feats: \\n\", node_feats)\n",
    "        node_feats = self.projection(node_feats)\n",
    "        print(\"Node feats after proj: \\n\", node_feats)\n",
    "        node_feats = node_feats.view(batch_size, num_nodes, self.num_heads, -1)\n",
    "\n",
    "        # Attention logits for each edge needs to be calculated\n",
    "        # doing this on all possible combinations is expensive\n",
    "        # => Create a tensor of [W*h_i||W*h_j] with i and j being the indices of all edges\n",
    "        edges = adj_matrix.nonzero(as_tuple=False) # return indices where adj matrix is non-zero\n",
    "        print(\"Edges: \\n\", edges)\n",
    "        node_feats_flat = node_feats.view(batch_size * num_nodes, self.num_heads, -1)\n",
    "        print(\"Node feats flat shape: \\n\", node_feats_flat.shape)\n",
    "        edge_indices_row = edges[:,0] * num_nodes + edges[:,1]\n",
    "        edge_indices_col = edges[:,0] * num_nodes + edges[:,2]\n",
    "        print(\"Edge indices row: \\n\", edge_indices_row)\n",
    "        print(\"Edge indices col: \\n\", edge_indices_col)\n",
    "\n",
    "        a_input = torch.cat([\n",
    "            torch.index_select(input=node_feats_flat, index=edge_indices_row, dim=0),\n",
    "            torch.index_select(input=node_feats_flat, index=edge_indices_col, dim=0)\n",
    "        ])\n",
    "\n",
    "        # calculate the attention MLP output (independent for each head)\n",
    "        attn_logits = torch.einsum(\"bhc,hc->bh\", a_input, self.a) # understand this better later\n",
    "        attn_logits = self.leakyrelu(attn_logits)\n",
    "\n",
    "        # map list of attention values back into a matrix\n",
    "        attn_matrix = attn_logits.new_zeros(adj_matrix.shape + (self.num_heads,)).fill_(-9e15)\n",
    "        attn_matrix[adj_matrix[...,None].repeat(1,1,1,self.num_heads) == 1] = attn_logits.reshape(-1)\n",
    "\n",
    "        # weighted average of attention\n",
    "        attn_probs = F.softmax(attn_matrix, dim=2)\n",
    "        if print_attn_probs:\n",
    "            print(\"Attention probs\\n\", attn_probs.permute(0,3,1,2))\n",
    "        node_feats = torch.einsum(\"bijh,bjhc->bihb\", attn_probs, node_feats)\n",
    "\n",
    "        # if heads should be concatenated, we can do this by reshaping. Otherwise, take mean\n",
    "        if self.concat_heads:\n",
    "            node_feats = node_feats.reshape(batch_size, num_nodes, -1)\n",
    "        else:\n",
    "            node_feats = node_feats.mean(dim=2)\n",
    "\n",
    "        return node_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adj matrix shape = \n",
      " torch.Size([1, 4, 4])\n",
      "Node feats: \n",
      " tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "Node feats after proj: \n",
      " tensor([[[0., 1.],\n",
      "         [2., 3.],\n",
      "         [4., 5.],\n",
      "         [6., 7.]]])\n",
      "Edges: \n",
      " tensor([[0, 0, 0],\n",
      "        [0, 0, 1],\n",
      "        [0, 1, 0],\n",
      "        [0, 1, 1],\n",
      "        [0, 1, 2],\n",
      "        [0, 1, 3],\n",
      "        [0, 2, 1],\n",
      "        [0, 2, 2],\n",
      "        [0, 2, 3],\n",
      "        [0, 3, 1],\n",
      "        [0, 3, 2],\n",
      "        [0, 3, 3]])\n",
      "Node feats flat shape: \n",
      " torch.Size([4, 2, 1])\n",
      "Edge indices row: \n",
      " tensor([0, 0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3])\n",
      "Edge indices col: \n",
      " tensor([0, 1, 0, 1, 2, 3, 1, 2, 3, 1, 2, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape mismatch: value tensor of shape [48] cannot be broadcast to indexing result of shape [24]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/johnathon/RL/deep_learning_tutorials/7 - GNN/GNNs.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/johnathon/RL/deep_learning_tutorials/7%20-%20GNN/GNNs.ipynb#ch0000012vscode-remote?line=3'>4</a>\u001b[0m layer\u001b[39m.\u001b[39ma\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([[\u001b[39m-\u001b[39m\u001b[39m0.2\u001b[39m, \u001b[39m0.3\u001b[39m], [\u001b[39m0.1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.1\u001b[39m]])\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/johnathon/RL/deep_learning_tutorials/7%20-%20GNN/GNNs.ipynb#ch0000012vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/johnathon/RL/deep_learning_tutorials/7%20-%20GNN/GNNs.ipynb#ch0000012vscode-remote?line=6'>7</a>\u001b[0m     out_feats \u001b[39m=\u001b[39m layer(node_feats, adj_matrix, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/johnathon/RL/deep_learning_tutorials/7%20-%20GNN/GNNs.ipynb#ch0000012vscode-remote?line=7'>8</a>\u001b[0m     print_attn_probs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/johnathon/RL/deep_learning_tutorials/7%20-%20GNN/GNNs.ipynb#ch0000012vscode-remote?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAdjacency matrix\u001b[39m\u001b[39m\"\u001b[39m, adj_matrix)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/johnathon/RL/deep_learning_tutorials/7%20-%20GNN/GNNs.ipynb#ch0000012vscode-remote?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInput features\u001b[39m\u001b[39m\"\u001b[39m, node_feats)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl2021/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/johnathon/miniconda3/envs/dl2021/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/johnathon/miniconda3/envs/dl2021/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/johnathon/miniconda3/envs/dl2021/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/johnathon/miniconda3/envs/dl2021/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/johnathon/miniconda3/envs/dl2021/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/johnathon/miniconda3/envs/dl2021/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/johnathon/miniconda3/envs/dl2021/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/johnathon/RL/deep_learning_tutorials/7 - GNN/GNNs.ipynb Cell 11'\u001b[0m in \u001b[0;36mGATLayer.forward\u001b[0;34m(self, node_feats, adj_matrix, print_attn_probs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/johnathon/RL/deep_learning_tutorials/7%20-%20GNN/GNNs.ipynb#ch0000011vscode-remote?line=64'>65</a>\u001b[0m \u001b[39m# map list of attention values back into a matrix\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/johnathon/RL/deep_learning_tutorials/7%20-%20GNN/GNNs.ipynb#ch0000011vscode-remote?line=65'>66</a>\u001b[0m attn_matrix \u001b[39m=\u001b[39m attn_logits\u001b[39m.\u001b[39mnew_zeros(adj_matrix\u001b[39m.\u001b[39mshape \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,))\u001b[39m.\u001b[39mfill_(\u001b[39m-\u001b[39m\u001b[39m9e15\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/johnathon/RL/deep_learning_tutorials/7%20-%20GNN/GNNs.ipynb#ch0000011vscode-remote?line=66'>67</a>\u001b[0m attn_matrix[adj_matrix[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\u001b[39mNone\u001b[39;00m]\u001b[39m.\u001b[39mrepeat(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m attn_logits\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/johnathon/RL/deep_learning_tutorials/7%20-%20GNN/GNNs.ipynb#ch0000011vscode-remote?line=68'>69</a>\u001b[0m \u001b[39m# weighted average of attention\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-18.04/home/johnathon/RL/deep_learning_tutorials/7%20-%20GNN/GNNs.ipynb#ch0000011vscode-remote?line=69'>70</a>\u001b[0m attn_probs \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(attn_matrix, dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape mismatch: value tensor of shape [48] cannot be broadcast to indexing result of shape [24]"
     ]
    }
   ],
   "source": [
    "layer = GATLayer(2, 2, num_heads=2)\n",
    "layer.projection.weight.data = torch.Tensor([[1., 0.], [0., 1.]]) # identity\n",
    "layer.projection.bias.data = torch.Tensor([0., 0.])\n",
    "layer.a.data = torch.Tensor([[-0.2, 0.3], [0.1, -0.1]])\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_feats = layer(node_feats, adj_matrix, \n",
    "    print_attn_probs=True)\n",
    "\n",
    "print(\"Adjacency matrix\", adj_matrix)\n",
    "print(\"Input features\", node_feats)\n",
    "print(\"Output features\", out_feats)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63040b782f21f547f736777bfca9e9bc589abae0bfbb4a789d74a688752a1988"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('dl2021')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
